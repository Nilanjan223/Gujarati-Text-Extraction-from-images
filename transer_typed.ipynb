{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7da5585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D # sliding window me se jo bhi maximum pixel hoga wo mil jaega\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acaf1423",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_dir_no_images = len(os.listdir(\"Gujarati/Train/A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d61236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ddf156a3d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_np_array = plt.imread(os.path.join(\"Gujarati/Train/A\",\n",
    "                                       os.listdir(\"Gujarati/Train/A\")[0]))\n",
    "plt.imshow(img_np_array, cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13241de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_cnn():\n",
    "    \n",
    "    input_layer=Input(shape=(32,32,3))\n",
    "\n",
    "    first_conv_layer= Conv2D(filters=25, kernel_size=(5,5), activation=\"relu\") (input_layer)\n",
    "\n",
    "    second_conv_layer=Conv2D(filters=50, kernel_size=(7,7), activation=\"relu\") (first_conv_layer)\n",
    "\n",
    "    max_pool_out=MaxPooling2D(pool_size=(6,6), strides=(6,6))(second_conv_layer)\n",
    "\n",
    "    flatten_layer=Flatten()(max_pool_out)\n",
    "\n",
    "    network_output_layer=Dense(units=385, activation=\"softmax\") (flatten_layer)\n",
    "    \n",
    "    return Model(inputs=input_layer, outputs=network_output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e63f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(32, 32, 3))\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "max_pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')(max_pool1)\n",
    "max_pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu')(max_pool2)\n",
    "max_pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "flatten_layer = Flatten()(max_pool3)\n",
    "dense1 = Dense(256, activation='relu')(flatten_layer)\n",
    "output_layer = Dense(385, activation='softmax')(dense1)  # Assuming num_classes is the number of output classes\n",
    "\n",
    "cnn = Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66283053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "____________________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   Trainable  \n",
      "============================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         Y          \n",
      "                                                                            \n",
      " conv2d_2 (Conv2D)           (None, 30, 30, 32)        896       Y          \n",
      "                                                                            \n",
      " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         Y          \n",
      " 2D)                                                                        \n",
      "                                                                            \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 64)        18496     Y          \n",
      "                                                                            \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         Y          \n",
      " 2D)                                                                        \n",
      "                                                                            \n",
      " conv2d_4 (Conv2D)           (None, 4, 4, 128)         73856     Y          \n",
      "                                                                            \n",
      " max_pooling2d_4 (MaxPooling  (None, 2, 2, 128)        0         Y          \n",
      " 2D)                                                                        \n",
      "                                                                            \n",
      " flatten_1 (Flatten)         (None, 512)               0         Y          \n",
      "                                                                            \n",
      " dense_2 (Dense)             (None, 256)               131328    Y          \n",
      "                                                                            \n",
      " dense_3 (Dense)             (None, 385)               98945     Y          \n",
      "                                                                            \n",
      "============================================================================\n",
      "Total params: 323,521\n",
      "Trainable params: 323,521\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "738bc348",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73a796e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.preprocessing.image.ImageDataGenerator object at 0x000001DDF18353A0>\n"
     ]
    }
   ],
   "source": [
    "print(datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "950fcefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53043 images belonging to 385 classes.\n"
     ]
    }
   ],
   "source": [
    "training_datagen = datagen.flow_from_directory(directory=\"Gujarati/Train\",\n",
    "                                               target_size=(32,32),\n",
    "                                               classes=os.listdir(\"Gujarati/Train\"),\n",
    "                                               batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a20c57a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23100 images belonging to 385 classes.\n"
     ]
    }
   ],
   "source": [
    "testing_datagen = datagen.flow_from_directory(directory=\"Gujarati/Test\",\n",
    "                                              target_size=(32,32),\n",
    "                                              classes=os.listdir(\"Gujarati/Test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b84860e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss=\"categorical_crossentropy\",\n",
    "                   metrics=[tf.keras.metrics.CategoricalAccuracy(),\n",
    "                            tf.keras.metrics.Precision(),\n",
    "                            tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cce86ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1ddf15f01f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97c79a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mb,Y_train_mb = training_datagen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "117698e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 385)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mb.shape\n",
    "\n",
    "Y_train_mb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24b5e54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 385)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_mb,Y_test_mb = testing_datagen.__next__()\n",
    "\n",
    "X_test_mb.shape\n",
    "\n",
    "Y_test_mb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "304ff57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 162s 2s/step - loss: 4.1804 - categorical_accuracy: 0.1722 - precision: 0.8234 - recall: 0.0225 - val_loss: 3.3788 - val_categorical_accuracy: 0.2728 - val_precision: 0.7313 - val_recall: 0.0853\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 57s 553ms/step - loss: 2.5828 - categorical_accuracy: 0.4296 - precision: 0.8357 - recall: 0.1945 - val_loss: 2.1840 - val_categorical_accuracy: 0.5095 - val_precision: 0.7658 - val_recall: 0.3483\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 57s 549ms/step - loss: 1.6713 - categorical_accuracy: 0.6139 - precision: 0.8648 - recall: 0.4182 - val_loss: 1.5310 - val_categorical_accuracy: 0.6394 - val_precision: 0.8170 - val_recall: 0.5308\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 55s 527ms/step - loss: 1.1113 - categorical_accuracy: 0.7373 - precision: 0.8929 - recall: 0.5902 - val_loss: 1.1124 - val_categorical_accuracy: 0.7282 - val_precision: 0.8347 - val_recall: 0.6618\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 53s 515ms/step - loss: 0.7697 - categorical_accuracy: 0.8148 - precision: 0.9113 - recall: 0.7096 - val_loss: 0.7300 - val_categorical_accuracy: 0.8059 - val_precision: 0.8765 - val_recall: 0.7658\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 54s 517ms/step - loss: 0.5448 - categorical_accuracy: 0.8668 - precision: 0.9325 - recall: 0.7920 - val_loss: 0.5653 - val_categorical_accuracy: 0.8527 - val_precision: 0.9017 - val_recall: 0.8263\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 54s 520ms/step - loss: 0.3995 - categorical_accuracy: 0.8995 - precision: 0.9450 - recall: 0.8473 - val_loss: 0.6202 - val_categorical_accuracy: 0.8380 - val_precision: 0.8783 - val_recall: 0.8147\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 56s 543ms/step - loss: 0.2975 - categorical_accuracy: 0.9245 - precision: 0.9555 - recall: 0.8862 - val_loss: 0.4029 - val_categorical_accuracy: 0.8945 - val_precision: 0.9194 - val_recall: 0.8807\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 55s 527ms/step - loss: 0.2227 - categorical_accuracy: 0.9412 - precision: 0.9625 - recall: 0.9145 - val_loss: 0.3711 - val_categorical_accuracy: 0.9088 - val_precision: 0.9272 - val_recall: 0.8988\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 54s 525ms/step - loss: 0.1753 - categorical_accuracy: 0.9545 - precision: 0.9695 - recall: 0.9338 - val_loss: 0.3881 - val_categorical_accuracy: 0.9051 - val_precision: 0.9217 - val_recall: 0.8968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd80797070>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(training_datagen,\n",
    "               epochs=10,\n",
    "               validation_data=testing_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b8d81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save_weights('custom_cnn_weights.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ee279db",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_to_exclude = 2  # specify the number of layers to exclude from the end\n",
    "\n",
    "# Get the total number of layers in the model\n",
    "total_layers = len(cnn.layers)\n",
    "\n",
    "# Extract weights of layers excluding the last `layers_to_exclude` layers\n",
    "weights_to_save = []\n",
    "for i in range(total_layers - layers_to_exclude):\n",
    "    weights_to_save.append(cnn.layers[i].get_weights())\n",
    "\n",
    "# Save the extracted weights\n",
    "np.save('custom_weights.npy', weights_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0fbd526",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('transfer_saved.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41174f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
