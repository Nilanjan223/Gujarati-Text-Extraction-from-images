{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e30758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character: ગ, Unicode Code Point: 2711\n",
      "Character: ુ, Unicode Code Point: 2753\n",
      "Character: જ, Unicode Code Point: 2716\n",
      "Character: ર, Unicode Code Point: 2736\n",
      "Character: ા, Unicode Code Point: 2750\n",
      "Character: ત, Unicode Code Point: 2724\n",
      "Character: ી, Unicode Code Point: 2752\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def segment_gujarati_paragraph(paragraph):\n",
    "    # Function to segment a Gujarati paragraph into characters and generate a dataset.\n",
    "\n",
    "    # Initialize an empty list to store character-label pairs\n",
    "    char_dataset = []\n",
    "\n",
    "    # Loop through each character in the paragraph\n",
    "    for char in paragraph:\n",
    "        # Skip whitespace characters\n",
    "        if unicodedata.category(char).startswith('Z'):\n",
    "            continue\n",
    "\n",
    "        # Get the Unicode code point of the character\n",
    "        char_code = ord(char)\n",
    "\n",
    "        # Append the character and its code point to the dataset\n",
    "        char_dataset.append((char, char_code))\n",
    "\n",
    "    return char_dataset\n",
    "\n",
    "# Example Gujarati paragraph (replace this with your own data)\n",
    "gujarati_paragraph = \"ગુજરાતી\"\n",
    "\n",
    "# Segment the paragraph into characters and generate the dataset\n",
    "dataset = segment_gujarati_paragraph(gujarati_paragraph)\n",
    "\n",
    "# Print the dataset\n",
    "for char, char_code in dataset:\n",
    "    print(f\"Character: {char}, Unicode Code Point: {char_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334fec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytesseract\n",
    "# from PIL import Image\n",
    "\n",
    "# # Path to the Tesseract executable (if not in your system PATH)\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'  # Update this path if necessary\n",
    "\n",
    "# # Load the image\n",
    "# image_path = 'img1.tif'  # Replace with the path to your image\n",
    "# img = Image.open(image_path)\n",
    "\n",
    "# # Perform OCR on the image to extract Gujarati text\n",
    "# print(pytesseract.get_languages(config=''))\n",
    "# text = pytesseract.image_to_string(img)\n",
    "\n",
    "# # Print the extracted text\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9451129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytesseract\n",
    "\n",
    "# # Test Tesseract installation\n",
    "# print(pytesseract.get_tesseract_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c3e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip show pytesseract-ocr-guj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "260dc57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pytesseract-ocr-guj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ddd803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4895b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e7ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "838a6915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8572bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18874643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2accb99",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f71e6fd",
   "metadata": {},
   "source": [
    "# SPLIT LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df26464e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 smaller images saved to the 'small_images' directory, excluding mostly blank images.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageStat\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Load the larger image\n",
    "large_image_path = 'INPUT/test8.jpg'  # Replace with the path to your larger image\n",
    "large_image = Image.open(large_image_path)\n",
    "\n",
    "# Define the size of each smaller image (100x100 pixels in this example)\n",
    "h = (int)(large_image.height / 14)\n",
    "w = (int)(large_image.width / 10)\n",
    "small_image_size = (w, h)\n",
    "\n",
    "# Calculate the number of smaller images to create\n",
    "num_rows = large_image.height // small_image_size[1]\n",
    "num_cols = large_image.width // small_image_size[0]\n",
    "\n",
    "# Create a blank image to compare with (adjust the color as needed)\n",
    "blank_color = (255, 255, 255)  # White\n",
    "blank_image = Image.new('RGB', small_image_size, blank_color)\n",
    "\n",
    "# Create a directory to store the smaller images\n",
    "output_directory = 'small_images'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get the current timestamp to make filenames unique\n",
    "timestamp = int(time.time())\n",
    "\n",
    "# Loop through the larger image and create and save only non-blank smaller images\n",
    "for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "        # Define the cropping coordinates for the current smaller image\n",
    "        left = col * small_image_size[0]\n",
    "        upper = row * small_image_size[1]\n",
    "        right = left + small_image_size[0]\n",
    "        lower = upper + small_image_size[1]\n",
    "\n",
    "        # Crop the smaller image\n",
    "        small_image = large_image.crop((left, upper, right, lower))\n",
    "\n",
    "        # Convert the cropped image to grayscale\n",
    "        small_image_gray = small_image.convert('L')\n",
    "\n",
    "        # Calculate the variance of pixel values in the grayscale image\n",
    "        stat = ImageStat.Stat(small_image_gray)\n",
    "        pixel_variance = stat.var[0]\n",
    "\n",
    "        # If the pixel variance is below a threshold, consider it blank (adjust the threshold as needed)\n",
    "        blank_threshold = 25  # Adjust as needed\n",
    "        if pixel_variance < blank_threshold:\n",
    "            continue  # Skip saving if mostly blank\n",
    "\n",
    "        # Generate a unique filename with a timestamp\n",
    "        small_image_path = os.path.join(output_directory, f'small_image_{timestamp}_{row}_{col}.png')\n",
    "        small_image.save(small_image_path)\n",
    "\n",
    "print(f\"{num_rows * num_cols} smaller images saved to the 'small_images' directory, excluding mostly blank images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5adb836",
   "metadata": {},
   "source": [
    "# BOUNDING BOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "511e2bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text region extracted and saved for small_image_1698345896_0_0.png\n",
      "Text region extracted and saved for small_image_1698345896_0_1.png\n",
      "No text found in small_image_1698345896_0_2.png\n",
      "No text found in small_image_1698345896_0_3.png\n",
      "No text found in small_image_1698345896_0_4.png\n",
      "No text found in small_image_1698345896_0_5.png\n",
      "No text found in small_image_1698345896_0_6.png\n",
      "No text found in small_image_1698345896_0_7.png\n",
      "No text found in small_image_1698345896_0_8.png\n",
      "Text region extracted and saved for small_image_1698345896_10_0.png\n",
      "Text region extracted and saved for small_image_1698345896_10_1.png\n",
      "Text region extracted and saved for small_image_1698345896_10_2.png\n",
      "Text region extracted and saved for small_image_1698345896_10_3.png\n",
      "Text region extracted and saved for small_image_1698345896_10_4.png\n",
      "Text region extracted and saved for small_image_1698345896_10_5.png\n",
      "Text region extracted and saved for small_image_1698345896_10_6.png\n",
      "Text region extracted and saved for small_image_1698345896_10_7.png\n",
      "Text region extracted and saved for small_image_1698345896_10_8.png\n",
      "Text region extracted and saved for small_image_1698345896_10_9.png\n",
      "Text region extracted and saved for small_image_1698345896_11_0.png\n",
      "Text region extracted and saved for small_image_1698345896_11_1.png\n",
      "Text region extracted and saved for small_image_1698345896_11_2.png\n",
      "Text region extracted and saved for small_image_1698345896_11_3.png\n",
      "Text region extracted and saved for small_image_1698345896_11_4.png\n",
      "Text region extracted and saved for small_image_1698345896_11_5.png\n",
      "Text region extracted and saved for small_image_1698345896_11_6.png\n",
      "Text region extracted and saved for small_image_1698345896_11_7.png\n",
      "Text region extracted and saved for small_image_1698345896_11_8.png\n",
      "Text region extracted and saved for small_image_1698345896_11_9.png\n",
      "Text region extracted and saved for small_image_1698345896_12_0.png\n",
      "Text region extracted and saved for small_image_1698345896_12_1.png\n",
      "Text region extracted and saved for small_image_1698345896_12_2.png\n",
      "Text region extracted and saved for small_image_1698345896_12_3.png\n",
      "Text region extracted and saved for small_image_1698345896_12_4.png\n",
      "Text region extracted and saved for small_image_1698345896_12_5.png\n",
      "Text region extracted and saved for small_image_1698345896_12_6.png\n",
      "Text region extracted and saved for small_image_1698345896_12_7.png\n",
      "Text region extracted and saved for small_image_1698345896_12_8.png\n",
      "Text region extracted and saved for small_image_1698345896_12_9.png\n",
      "Text region extracted and saved for small_image_1698345896_13_0.png\n",
      "Text region extracted and saved for small_image_1698345896_13_1.png\n",
      "Text region extracted and saved for small_image_1698345896_13_2.png\n",
      "Text region extracted and saved for small_image_1698345896_13_3.png\n",
      "Text region extracted and saved for small_image_1698345896_13_4.png\n",
      "No text found in small_image_1698345896_13_5.png\n",
      "Text region extracted and saved for small_image_1698345896_13_6.png\n",
      "Text region extracted and saved for small_image_1698345896_13_7.png\n",
      "Text region extracted and saved for small_image_1698345896_13_8.png\n",
      "Text region extracted and saved for small_image_1698345896_13_9.png\n",
      "No text found in small_image_1698345896_1_0.png\n",
      "No text found in small_image_1698345896_1_1.png\n",
      "No text found in small_image_1698345896_1_2.png\n",
      "No text found in small_image_1698345896_1_3.png\n",
      "No text found in small_image_1698345896_1_4.png\n",
      "No text found in small_image_1698345896_1_5.png\n",
      "No text found in small_image_1698345896_1_6.png\n",
      "No text found in small_image_1698345896_1_7.png\n",
      "No text found in small_image_1698345896_1_9.png\n",
      "No text found in small_image_1698345896_2_0.png\n",
      "No text found in small_image_1698345896_2_1.png\n",
      "No text found in small_image_1698345896_2_2.png\n",
      "Text region extracted and saved for small_image_1698345896_2_3.png\n",
      "No text found in small_image_1698345896_2_4.png\n",
      "No text found in small_image_1698345896_2_5.png\n",
      "No text found in small_image_1698345896_2_6.png\n",
      "No text found in small_image_1698345896_2_7.png\n",
      "No text found in small_image_1698345896_2_8.png\n",
      "Text region extracted and saved for small_image_1698345896_3_0.png\n",
      "Text region extracted and saved for small_image_1698345896_3_1.png\n",
      "No text found in small_image_1698345896_3_2.png\n",
      "No text found in small_image_1698345896_3_3.png\n",
      "No text found in small_image_1698345896_3_4.png\n",
      "No text found in small_image_1698345896_3_5.png\n",
      "No text found in small_image_1698345896_3_6.png\n",
      "No text found in small_image_1698345896_3_7.png\n",
      "Text region extracted and saved for small_image_1698345896_3_8.png\n",
      "No text found in small_image_1698345896_3_9.png\n",
      "Text region extracted and saved for small_image_1698345896_4_0.png\n",
      "Text region extracted and saved for small_image_1698345896_4_1.png\n",
      "Text region extracted and saved for small_image_1698345896_4_2.png\n",
      "Text region extracted and saved for small_image_1698345896_4_3.png\n",
      "Text region extracted and saved for small_image_1698345896_4_4.png\n",
      "No text found in small_image_1698345896_4_5.png\n",
      "No text found in small_image_1698345896_4_6.png\n",
      "No text found in small_image_1698345896_4_7.png\n",
      "Text region extracted and saved for small_image_1698345896_4_8.png\n",
      "No text found in small_image_1698345896_4_9.png\n",
      "Text region extracted and saved for small_image_1698345896_5_0.png\n",
      "Text region extracted and saved for small_image_1698345896_5_1.png\n",
      "Text region extracted and saved for small_image_1698345896_5_2.png\n",
      "Text region extracted and saved for small_image_1698345896_5_3.png\n",
      "Text region extracted and saved for small_image_1698345896_5_4.png\n",
      "No text found in small_image_1698345896_5_5.png\n",
      "No text found in small_image_1698345896_5_6.png\n",
      "No text found in small_image_1698345896_5_7.png\n",
      "No text found in small_image_1698345896_5_9.png\n",
      "Text region extracted and saved for small_image_1698345896_6_0.png\n",
      "Text region extracted and saved for small_image_1698345896_6_1.png\n",
      "Text region extracted and saved for small_image_1698345896_6_2.png\n",
      "Text region extracted and saved for small_image_1698345896_6_3.png\n",
      "Text region extracted and saved for small_image_1698345896_6_4.png\n",
      "Text region extracted and saved for small_image_1698345896_6_5.png\n",
      "No text found in small_image_1698345896_6_6.png\n",
      "No text found in small_image_1698345896_6_7.png\n",
      "Text region extracted and saved for small_image_1698345896_6_8.png\n",
      "Text region extracted and saved for small_image_1698345896_6_9.png\n",
      "Text region extracted and saved for small_image_1698345896_7_0.png\n",
      "Text region extracted and saved for small_image_1698345896_7_1.png\n",
      "Text region extracted and saved for small_image_1698345896_7_2.png\n",
      "Text region extracted and saved for small_image_1698345896_7_3.png\n",
      "Text region extracted and saved for small_image_1698345896_7_4.png\n",
      "No text found in small_image_1698345896_7_5.png\n",
      "Text region extracted and saved for small_image_1698345896_7_6.png\n",
      "No text found in small_image_1698345896_7_7.png\n",
      "Text region extracted and saved for small_image_1698345896_7_8.png\n",
      "Text region extracted and saved for small_image_1698345896_7_9.png\n",
      "Text region extracted and saved for small_image_1698345896_8_0.png\n",
      "Text region extracted and saved for small_image_1698345896_8_1.png\n",
      "Text region extracted and saved for small_image_1698345896_8_2.png\n",
      "Text region extracted and saved for small_image_1698345896_8_3.png\n",
      "Text region extracted and saved for small_image_1698345896_8_4.png\n",
      "Text region extracted and saved for small_image_1698345896_8_5.png\n",
      "Text region extracted and saved for small_image_1698345896_8_6.png\n",
      "Text region extracted and saved for small_image_1698345896_8_7.png\n",
      "Text region extracted and saved for small_image_1698345896_8_8.png\n",
      "No text found in small_image_1698345896_8_9.png\n",
      "Text region extracted and saved for small_image_1698345896_9_0.png\n",
      "Text region extracted and saved for small_image_1698345896_9_1.png\n",
      "Text region extracted and saved for small_image_1698345896_9_2.png\n",
      "Text region extracted and saved for small_image_1698345896_9_3.png\n",
      "Text region extracted and saved for small_image_1698345896_9_4.png\n",
      "Text region extracted and saved for small_image_1698345896_9_5.png\n",
      "Text region extracted and saved for small_image_1698345896_9_6.png\n",
      "Text region extracted and saved for small_image_1698345896_9_7.png\n",
      "Text region extracted and saved for small_image_1698345896_9_8.png\n",
      "Text region extracted and saved for small_image_1698345896_9_9.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function to extract the region containing text\n",
    "def extract_text_region(image_path):\n",
    "    # Your existing code here...\n",
    "    # Read the input image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise and improve edge detection\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Use Canny edge detection to find edges in the image\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    # Find contours in the edges image\n",
    "    contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Initialize bounding box coordinates\n",
    "    x_min, x_max, y_min, y_max = float('inf'), -1, float('inf'), -1\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        x_min = min(x_min, x)\n",
    "        y_min = min(y_min, y)\n",
    "        x_max = max(x_max, x + w)\n",
    "        y_max = max(y_max, y + h)\n",
    "    \n",
    "    # Extract the text region\n",
    "    if x_min < x_max and y_min < y_max:\n",
    "    # Extract the text region\n",
    "        text_region = image[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
    "    else:\n",
    "        text_region = None\n",
    "    \n",
    "    return text_region\n",
    "\n",
    "# Input and output folder paths\n",
    "input_folder = 'small_images'\n",
    "output_folder = 'output_text_images'\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through all files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.tif') or filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Construct the full path of the input image\n",
    "        input_image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Extract the text region\n",
    "        text_image = extract_text_region(input_image_path)\n",
    "\n",
    "        # Construct the full path of the output image\n",
    "        output_image_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        # Save the new image containing the text region\n",
    "        if text_image is not None:\n",
    "            cv2.imwrite(output_image_path, text_image)\n",
    "            print(f'Text region extracted and saved for {filename}')\n",
    "        else:\n",
    "            print(f'No text found in {filename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be10a7",
   "metadata": {},
   "source": [
    "# RESIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b06a79a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Set the folder path containing images to be resized\n",
    "folder_path = r'C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\output_text_images'\n",
    "\n",
    "# Define the new width and height for the resized image\n",
    "new_width = 32\n",
    "new_height = 32\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file in files:\n",
    "    # Check if the file is an image\n",
    "    if file.endswith('.jpg') or file.endswith('.png') or file.endswith('.jpeg'):\n",
    "        # Load the image\n",
    "        image_path = os.path.join(folder_path, file)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Resize the image\n",
    "        resized_image = cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "        # Overwrite the existing image with the resized image\n",
    "        cv2.imwrite(image_path, resized_image)\n",
    "\n",
    "#         print(f'Resized and saved: {file}')\n",
    "\n",
    "print('Resizing complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c87574",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82c0c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "\n",
    "# Set the input folder path\n",
    "train_folder = r'C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\Dataset\\Test'\n",
    "\n",
    "# Initialize the ImageDataGenerator for augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Get a list of all subfolders in the train folder\n",
    "subfolders = [f.path for f in os.scandir(train_folder) if f.is_dir()]\n",
    "\n",
    "# Loop through each subfolder\n",
    "for folder in subfolders:\n",
    "    # Get a list of all files in the subfolder\n",
    "    files = os.listdir(folder)\n",
    "\n",
    "    # Loop through each file in the subfolder\n",
    "    for file in files:\n",
    "        # Check if the file is an image\n",
    "        if file.endswith('.jpg') or file.endswith('.png') or file.endswith('.jpeg'):\n",
    "            # Load the image\n",
    "            image_path = os.path.join(folder, file)\n",
    "            image = np.array(Image.open(image_path))\n",
    "            image = image.reshape((1,) + image.shape)  # Reshape the image for the flow method\n",
    "\n",
    "            # Generate augmented images and save in the same folder\n",
    "            i = 0\n",
    "            for batch in datagen.flow(image, batch_size=1, save_to_dir=folder, save_prefix='aug', save_format='jpeg'):\n",
    "                i += 1\n",
    "                if i >= 10:  # Generate 10 augmented images for each original image\n",
    "                    break\n",
    "\n",
    "#             print(f'Augmented and saved images for: {file} in folder: {folder}')\n",
    "\n",
    "print('Augmentation complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b35ba245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "# TEST1\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from PIL import Image\n",
    "\n",
    "# # Set the input and output folder paths\n",
    "# input_folder = r'C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\output_text_images'\n",
    "# output_folder = r'C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\augmented_images'\n",
    "\n",
    "# # Ensure the output folder exists, if not, create it\n",
    "# if not os.path.exists(output_folder):\n",
    "#     os.makedirs(output_folder)\n",
    "\n",
    "# # Initialize the ImageDataGenerator for augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=40,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=False,\n",
    "#     fill_mode='nearest')\n",
    "\n",
    "# # Get a list of all files in the input folder\n",
    "# files = os.listdir(input_folder)\n",
    "\n",
    "# # Loop through each file in the input folder\n",
    "# for file in files:\n",
    "#     # Check if the file is an image\n",
    "#     if file.endswith('.jpg') or file.endswith('.png') or file.endswith('.jpeg'):\n",
    "#         # Load the image\n",
    "#         image = np.array(Image.open(image_path))\n",
    "#         image = image.reshape((1,) + image.shape)  # Reshape the image for the flow method\n",
    "\n",
    "#         # Generate augmented images\n",
    "#         i = 0\n",
    "#         for batch in datagen.flow(image, batch_size=1, save_to_dir=output_folder, save_prefix=file.split('.')[0], save_format='jpeg'):\n",
    "#             i += 1\n",
    "#             if i >= 10:  # Generate 10 augmented images for each original image\n",
    "#                 break\n",
    "\n",
    "# #         print(f'Augmented and saved images for: {file}')\n",
    "\n",
    "# print('Augmentation complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1717028a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented and saved images for: small_image_1695482881_3_0.png\n",
      "Augmented and saved images for: small_image_1695482881_3_1.png\n",
      "Augmented and saved images for: small_image_1695482881_3_2.png\n",
      "Augmented and saved images for: small_image_1695482881_3_3.png\n",
      "Augmented and saved images for: small_image_1695482881_3_4.png\n",
      "Augmented and saved images for: small_image_1695482881_3_5.png\n",
      "Augmented and saved images for: small_image_1695482881_3_7.png\n",
      "Augmented and saved images for: small_image_1695482881_3_8.png\n",
      "Augmented and saved images for: small_image_1695482881_3_9.png\n",
      "Augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "# TEST2\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from PIL import Image\n",
    "\n",
    "# # Set the input and output folder paths\n",
    "# input_folder = r'C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\Dataset\\Train\\ba'\n",
    "# # output_folder = 'path/to/output/folder'\n",
    "\n",
    "# # Ensure the output folder exists, if not, create it\n",
    "# # if not os.path.exists(output_folder):\n",
    "# #     os.makedirs(output_folder)\n",
    "\n",
    "# # Initialize the ImageDataGenerator for augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=0,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.1,\n",
    "#     fill_mode='nearest')\n",
    "\n",
    "# # Get a list of all files in the input folder\n",
    "# files = os.listdir(input_folder)\n",
    "\n",
    "# # Loop through each file in the input folder\n",
    "# for file in files:\n",
    "#     # Check if the file is an image\n",
    "#     if file.endswith('.jpg') or file.endswith('.png') or file.endswith('.jpeg'):\n",
    "#         # Load the image\n",
    "#         image_path = os.path.join(input_folder, file)\n",
    "#         image = np.array(Image.open(image_path))\n",
    "#         image = image.reshape((1,) + image.shape)  # Reshape the image for the flow method\n",
    "\n",
    "#         # Generate augmented images and save in the same folder\n",
    "#         i = 0\n",
    "#         for batch in datagen.flow(image, batch_size=1, save_to_dir=input_folder, save_prefix='aug', save_format='jpeg'):\n",
    "#             i += 1\n",
    "#             if i >= 10:  # Generate 10 augmented images for each original image\n",
    "#                 break\n",
    "\n",
    "#         print(f'Augmented and saved images for: {file}')\n",
    "\n",
    "# print('Augmentation complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e85deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented and saved images for: small_image_1695482881_3_0.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\ba\n",
      "Augmented and saved images for: small_image_1695482881_3_1.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\ba\n",
      "Augmented and saved images for: small_image_1695482881_3_2.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\ba\n",
      "Augmented and saved images for: small_image_1695482881_3_3.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\ba\n",
      "Augmented and saved images for: small_image_1695482881_3_4.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\ba\n",
      "Augmented and saved images for: small_image_1695482881_3_5.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\ba\n",
      "Augmented and saved images for: small_image_1695482881_3_7.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\ba\n",
      "Augmented and saved images for: small_image_1695482881_3_8.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\ba\n",
      "Augmented and saved images for: small_image_1695482881_3_9.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\ba\n",
      "Augmented and saved images for: small_image_1695482881_4_0.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\bha\n",
      "Augmented and saved images for: small_image_1695482881_4_1.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\bha\n",
      "Augmented and saved images for: small_image_1695482881_4_2.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\bha\n",
      "Augmented and saved images for: small_image_1695482881_4_3.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\bha\n",
      "Augmented and saved images for: small_image_1695482881_4_5.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\bha\n",
      "Augmented and saved images for: small_image_1695482881_4_6.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\bha\n",
      "Augmented and saved images for: small_image_1695482881_4_9.png in folder: C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder\\bha\n",
      "Augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "\n",
    "# Set the input folder path\n",
    "train_folder = r'C:\\Users\\Nilanjan Vyas\\Documents\\Minor_Project\\TestFolder'\n",
    "\n",
    "# Initialize the ImageDataGenerator for augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Get a list of all subfolders in the train folder\n",
    "subfolders = [f.path for f in os.scandir(train_folder) if f.is_dir()]\n",
    "\n",
    "# Loop through each subfolder\n",
    "for folder in subfolders:\n",
    "    # Get a list of all files in the subfolder\n",
    "    files = os.listdir(folder)\n",
    "\n",
    "    # Loop through each file in the subfolder\n",
    "    for file in files:\n",
    "        # Check if the file is an image\n",
    "        if file.endswith('.jpg') or file.endswith('.png') or file.endswith('.jpeg'):\n",
    "            # Load the image\n",
    "            image_path = os.path.join(folder, file)\n",
    "            image = np.array(Image.open(image_path))\n",
    "            image = image.reshape((1,) + image.shape)  # Reshape the image for the flow method\n",
    "\n",
    "            # Generate augmented images and save in the same folder\n",
    "            i = 0\n",
    "            for batch in datagen.flow(image, batch_size=1, save_to_dir=folder, save_prefix='aug', save_format='jpeg'):\n",
    "                i += 1\n",
    "                if i >= 10:  # Generate 10 augmented images for each original image\n",
    "                    break\n",
    "\n",
    "            print(f'Augmented and saved images for: {file} in folder: {folder}')\n",
    "\n",
    "print('Augmentation complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453416d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
